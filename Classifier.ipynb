{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0'\n",
    "subdirectories = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "opened_files = []\n",
    "closed_files = []\n",
    "\n",
    "for subdirectory in subdirectories:\n",
    "    files = os.listdir(subdirectory)\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file[-6:] == '01.edf':\n",
    "                # This is data for eyes opened\n",
    "                eyes_opened = os.path.join(subdirectory, file)\n",
    "                opened_files.append(eyes_opened)\n",
    "            if file[-6:] == '02.edf':\n",
    "                # This is data for eyes closed\n",
    "                eyes_closed = os.path.join(subdirectory, file)\n",
    "                closed_files.append(eyes_closed)\n",
    "    else:\n",
    "        print(f\"No files found in {subdirectory}\")\n",
    "\n",
    "large_open_data_raw = []\n",
    "large_closed_data_raw = []\n",
    "\n",
    "flag = True\n",
    "\n",
    "for i in range(len(opened_files)):\n",
    "    if i not in [1,4,5,6,12,13,15,17,19,22,29,31,33,34.47,50,51,58,60,71,76,77,79,81,86,87,88,90,95,100]:\n",
    "        data1 = mne.io.read_raw_edf(opened_files[i], preload=True, verbose=False).get_data(verbose=False)\n",
    "        data2 = mne.io.read_raw_edf(closed_files[i], preload=True, verbose=False).get_data(verbose=False)\n",
    "        for j in range(max(len(data1), len(data2))):\n",
    "            if len(data1[j]) != 9760 or len(data2[j]) != 9760:\n",
    "                flag = False\n",
    "        if flag:\n",
    "            large_open_data_raw.append(data1)\n",
    "            large_closed_data_raw.append(data2)\n",
    "        flag = True\n",
    "\n",
    "print(large_open_data_raw.__len__())\n",
    "print(large_closed_data_raw.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(large_open_data_raw)):\n",
    "    if len(large_open_data_raw[i]) != 64:\n",
    "        print(i)\n",
    "    for j in range(len(large_open_data_raw[i])):\n",
    "        if len(large_open_data_raw[i][j]) != 9760:\n",
    "            print(i)\n",
    "\n",
    "for i in range(len(large_closed_data_raw)):\n",
    "    if len(large_closed_data_raw[i]) != 64:\n",
    "        print(i)\n",
    "    for j in range(len(large_closed_data_raw[i])):\n",
    "        if len(large_closed_data_raw[i][j]) != 9760:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_channel_plot(data, channel, title):\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(data[channel, :])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_channels(data, title):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(data.T)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_channels_subplots(data):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(64):\n",
    "        plt.subplot(8, 8, i+1)\n",
    "        plt.plot(data[i, :])\n",
    "        plt.title(f\"Channel {i}\")\n",
    "    plt.show()\n",
    "\n",
    "single_channel_plot(large_open_data_raw[0], 0, \"Channel 0 for eyes opened\")\n",
    "single_channel_plot(large_closed_data_raw[0], 0, \"Channel 0 for eyes closed\")\n",
    "plot_all_channels(large_open_data_raw[0], \"All channels for eyes opened\")\n",
    "plot_all_channels(large_closed_data_raw[0], \"All channels for eyes closed\")\n",
    "plot_all_channels_subplots(large_open_data_raw[0])\n",
    "plot_all_channels_subplots(large_closed_data_raw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_closed_data = []\n",
    "large_open_data = []\n",
    "\n",
    "# Define the frequency range for the filter\n",
    "low_freq = 0.1  # Low-pass frequency in Hz\n",
    "high_freq = 35 # High-pass frequency in Hz\n",
    "\n",
    "for data in opened_files:\n",
    "    data1 = mne.io.read_raw_edf(data, preload=True, verbose=False)\n",
    "    data1 = mne.filter.filter_data(data1.get_data(), sfreq=data1.info['sfreq'], l_freq=low_freq, h_freq=high_freq, fir_design=\"firwin\", verbose=False)\n",
    "    eeg_data1 = data1\n",
    "    large_open_data.append(eeg_data1)\n",
    "\n",
    "for data in closed_files:\n",
    "    data1 = mne.io.read_raw_edf(data, preload=True, verbose=False)\n",
    "    data1 = mne.filter.filter_data(data1.get_data(), sfreq=data1.info['sfreq'], l_freq=low_freq, h_freq=high_freq, fir_design=\"firwin\", verbose=False)\n",
    "    eeg_data1 = data1\n",
    "    large_closed_data.append(eeg_data1)\n",
    "\n",
    "plot_all_channels(large_open_data[0], \"All channels for eyes opened\")\n",
    "plot_all_channels(large_closed_data[0], \"All channels for eyes closed\")\n",
    "plot_all_channels_subplots(large_open_data_raw[0])\n",
    "plot_all_channels_subplots(large_open_data[0])\n",
    "plot_all_channels_subplots(large_closed_data_raw[0])\n",
    "plot_all_channels_subplots(large_closed_data[0])\n",
    "\n",
    "\n",
    "for i in range(len(large_closed_data)):\n",
    "    if len(large_closed_data[i]) != 64:\n",
    "        print(i)\n",
    "    for j in range(len(large_closed_data[i])):\n",
    "        if len(large_closed_data[i][j]) != 9760:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Channel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "all_test_accuracies = []\n",
    "\n",
    "\n",
    "class FNNClassifierSingle(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FNNClassifierSingle, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = 9760\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "for channel in range(63):\n",
    "    data = np.concatenate((np.array(large_open_data_raw)[:, channel, :], np.array(large_closed_data_raw)[:, channel, :]), axis=0)\n",
    "    labels = np.concatenate((np.zeros(len(np.array(large_open_data_raw)[:, channel, :])), np.ones(len(np.array(large_closed_data_raw)[:, channel, :]))), axis=0)\n",
    "    data = torch.Tensor(data).to(device)\n",
    "    labels = torch.Tensor(labels).to(device)\n",
    "    labels = labels.long()\n",
    "\n",
    "    random_indices = np.arange(len(data))\n",
    "    np.random.shuffle(random_indices)\n",
    "    data = data[random_indices]\n",
    "    labels = labels[random_indices]\n",
    "\n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    test_size = 0.2 \n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    train_data = torch.Tensor(train_data)\n",
    "    train_labels = torch.Tensor(train_labels)\n",
    "    test_data = torch.Tensor(test_data)\n",
    "    test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_labels)\n",
    "    test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    fnn_model = FNNClassifierSingle(input_size, hidden_size, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(fnn_model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 100\n",
    "    losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader: \n",
    "            optimizer.zero_grad()\n",
    "            outputs = fnn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        losses.append(epoch_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader: \n",
    "                outputs = fnn_model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(test_accuracies)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Test Set Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    final_test_accuracy = test_accuracies[-1]\n",
    "    all_losses.append(losses[-1])\n",
    "    all_test_accuracies.append(test_accuracies[-1])\n",
    "    print(f'Final accuracy on the test dataset: {final_test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNClassifierSingle(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FNNClassifierSingle, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = 9760\n",
    "hidden_size = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_losses)\n",
    "plt.xlabel('Channel #')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Set Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(all_test_accuracies)\n",
    "plt.xlabel('Channel #')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Set Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "data = np.concatenate((np.array(large_open_data_raw)[:, channel, :], np.array(large_closed_data_raw)[:, channel, :]), axis=0)\n",
    "labels = np.concatenate((np.zeros(len(np.array(large_open_data_raw)[:, channel, :])), np.ones(len(np.array(large_closed_data_raw)[:, channel, :]))), axis=0)\n",
    "data = torch.Tensor(data).to(device)\n",
    "labels = torch.Tensor(labels).to(device)\n",
    "labels = labels.long()\n",
    "\n",
    "random_indices = np.arange(len(data))\n",
    "np.random.shuffle(random_indices)\n",
    "data = data[random_indices]\n",
    "labels = labels[random_indices]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "test_size = 0.2 \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "train_data = torch.Tensor(train_data)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class FNNClassifierSingle(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FNNClassifierSingle, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = 9760\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "fnn_model = FNNClassifierSingle(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fnn_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2000\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        outputs = fnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader: \n",
    "        outputs = fnn_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test dataset: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Channel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor(\n",
    "    np.concatenate((\n",
    "        np.array(large_closed_data_raw), np.array(large_open_data_raw)), axis=0)).to(device)\n",
    "\n",
    "labels = torch.Tensor(\n",
    "    np.concatenate((\n",
    "        np.zeros(len(np.array(large_closed_data_raw))), np.ones(len(np.array(large_open_data_raw)))), axis=0)).to(device).long()\n",
    "\n",
    "random_indices = np.arange(len(data))\n",
    "np.random.shuffle(random_indices)\n",
    "data = data[random_indices]\n",
    "labels = labels[random_indices]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "test_size = 0.2 \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "train_data = torch.Tensor(train_data)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FNNClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = 9760  * 64\n",
    "hidden_size = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_model = FNNClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fnn_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 500\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "best_test_loss = float('inf')\n",
    "patience = 20 \n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        outputs = fnn_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}] Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(test_accuracies)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Test Set Accuracy')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader: \n",
    "            outputs = fnn_model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "\n",
    "    if no_improvement >= patience:\n",
    "        print(f'Early stopping after {epoch} epochs due to no improvement in test loss.')\n",
    "        break\n",
    "\n",
    "final_test_accuracy = test_accuracies[-1]\n",
    "print(f'Final accuracy on the test dataset: {final_test_accuracy:.2f}%')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Set Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
