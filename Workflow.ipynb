{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the data, we'll use the Data folder which contains ways to download data. Here we'll start off by using the EEG_BCI motor imagery dataset.\n",
    "\n",
    "If we want to download the entire dataset, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import download_EEGBCI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"Are you sure you want to download the entire dataset? (Y/N)\") in \"Yy\":\n",
    "    total_subjects = list(range(1, 110))\n",
    "    runs = list(range(1, 15))\n",
    "    download_EEGBCI(total_subjects, runs, './EEGData', False)\n",
    "    print(\"Downloaded everything!\")\n",
    "\n",
    "else:\n",
    "    print(\"Download cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we only want to download the first 3 subjects and the first 3 runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [1, 2, 3]\n",
    "runs = [1, 2, 3]\n",
    "download_EEGBCI(subjects, runs, './EEGData', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is critical for actually getting the data into the ML algorithms. To do this, we'll have to rely on MNE's import functions to load the data into a format that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0'\n",
    "\n",
    "subdirectories = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "\n",
    "opened_files = []\n",
    "closed_files = []\n",
    "\n",
    "for subdirectory in subdirectories:\n",
    "    files = os.listdir(subdirectory)\n",
    "    \n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            \n",
    "            if file[-6:] == '01.edf':\n",
    "                # This is data for eyes opened\n",
    "                eyes_opened = os.path.join(subdirectory, file)\n",
    "                print(eyes_opened)\n",
    "                opened_files.append(eyes_opened)\n",
    "\n",
    "            if file[-6:] == '02.edf':\n",
    "                # This is data for eyes closed\n",
    "                eyes_closed = os.path.join(subdirectory, file)\n",
    "                print(eyes_closed)\n",
    "                closed_files.append(eyes_closed)\n",
    "    else:\n",
    "        print(f\"No files found in {subdirectory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_open_data = []\n",
    "# This is a list of all the data for eyes opened\n",
    "\n",
    "for data in opened_files:\n",
    "    large_open_data.append(mne.io.read_raw_edf(data, preload=True, verbose=False).get_data(verbose=False))\n",
    "\n",
    "large_closed_data = []\n",
    "# This is a list of all the data for eyes closed\n",
    "\n",
    "for data in closed_files:\n",
    "    large_closed_data.append(mne.io.read_raw_edf(data, preload=True, verbose=False).get_data(verbose=False))\n",
    "\n",
    "\n",
    "# This is the number of files for eyes opened\n",
    "print(large_open_data.__len__())\n",
    "# This is the number of files for eyes closed\n",
    "print(large_closed_data.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Detailed Ways of Working With MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/\"\n",
    "raw = mne.io.read_raw_edf('./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf', preload=True)\n",
    "annotations = raw.annotations\n",
    "annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_descriptions, event_counts = np.unique(annotations.description, return_counts=True)\n",
    "\n",
    "# Print event descriptions and their counts\n",
    "for desc, count in zip(event_descriptions, event_counts):\n",
    "    print(f\"Event: {desc}, Count: {count}\")\n",
    "\n",
    "# Select specific event type (replace 'event_type' with your desired event description)\n",
    "event_type = 'event_type'\n",
    "events = annotations[annotations.description == event_type]\n",
    "\n",
    "# Print out event onset times and durations\n",
    "for idx, event in enumerate(events):\n",
    "    print(f\"Event {idx + 1}: Onset: {event['onset']:.2f}, Duration: {event['duration']:.2f}\")\n",
    "\n",
    "# Replace 'your_file.edf' with the actual path to your EDF file\n",
    "raw =  mne.io.read_raw_edf('./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf', preload=True)\n",
    "\n",
    "# Get EEG data for all channels\n",
    "eeg_data = raw.get_data()\n",
    "\n",
    "# Print the shape of the EEG data array\n",
    "print(\"EEG data shape:\", eeg_data.shape)\n",
    "\n",
    "# List of EDF file paths\n",
    "edf_files = ['./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf', \n",
    "'./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf',\n",
    "'./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf']\n",
    "\n",
    "# List comprehension to read all EDF files\n",
    "raw_list = [mne.io.read_raw_edf(edf_file, preload=True) for edf_file in edf_files]\n",
    "\n",
    "# Extract EEG data for all channels from each raw object\n",
    "eeg_data_list = [raw.get_data() for raw in raw_list]\n",
    "\n",
    "# Print the shape of the EEG data arrays for each file\n",
    "for idx, eeg_data in enumerate(eeg_data_list):\n",
    "    print(f\"EEG data shape for file {edf_files[idx]}:\", eeg_data.shape)\n",
    "\n",
    "raw_list[0].plot(scalings='auto', title='EEG Channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_plot(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "    eeg_data = data.get_data()\n",
    "    time = data.times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for ch_idx in range(eeg_data.shape[0]):\n",
    "        plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('EEG Data for All Channels')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_plot(file1, file2):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle('Eyes Opened vs Eyes Closed')\n",
    "\n",
    "    data1 = mne.io.read_raw_edf(file1, preload=True, verbose=False)\n",
    "    data1.filter(1.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\", verbose=False)\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800, verbose=False)\n",
    "    ica.fit(data1, verbose=False)\n",
    "    ica.exclude = [1, 2]\n",
    "    data1 = ica.apply(data1, verbose=False)\n",
    "\n",
    "    \n",
    "    data2 = mne.io.read_raw_edf(file2, preload=True, verbose=False)\n",
    "    data2.filter(1.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\", verbose=False)\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800, verbose=False)\n",
    "    ica.fit(data2, verbose=False)\n",
    "    ica.exclude = [1, 2]\n",
    "    data2 = ica.apply(data2, verbose=False)\n",
    "    \n",
    "\n",
    "    good_channels1 = data1.info['ch_names']\n",
    "    good_channels2 = data2.info['ch_names']\n",
    "\n",
    "    eeg_data1 = data1.get_data(picks=good_channels1)\n",
    "    eeg_data2 = data2.get_data(picks=good_channels2)\n",
    "\n",
    "    time = data1.times\n",
    "\n",
    "    ax1.plot(time, eeg_data1[0])\n",
    "    ax1.set_title('Eyes Opened')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    for ch_idx in range(eeg_data1.shape[0]):\n",
    "        ax1.plot(time, eeg_data1[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    ax1.set_xlim(0, 5)\n",
    "    ax1.set_ylim(-0.0002, 0.0002)\n",
    "\n",
    "    ax2.plot(time, eeg_data2[0])\n",
    "    ax2.set_title('Eyes Closed')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Amplitude')\n",
    "    for ch_idx in range(eeg_data2.shape[0]):\n",
    "        ax2.plot(time, eeg_data2[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    ax2.set_xlim(0, 5)\n",
    "    ax2.set_ylim(-0.0002, 0.0002)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_plot(opened_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    double_plot(opened_files[i], closed_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd(fmax=50).plot(picks=\"data\", exclude=\"bads\")\n",
    "raw.plot(duration=5, n_channels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw EEG data\n",
    "edf_file = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R01.edf'\n",
    "raw = mne.io.read_raw_edf(edf_file, preload=True, verbose=False)\n",
    "\n",
    "\n",
    "def compute_psd(data, fs, nperseg=256, noverlap=None):\n",
    "    \"\"\"\n",
    "    Compute Power Spectral Density (PSD) using the Welch method.\n",
    "\n",
    "    Parameters:\n",
    "        data (array): EEG data array with shape (n_channels, n_samples).\n",
    "        fs (float): Sampling frequency.\n",
    "        nperseg (int): Length of each segment for PSD estimation.\n",
    "        noverlap (int): Number of overlapping samples between segments.\n",
    "    \n",
    "    Returns:\n",
    "        freqs (array): Frequency values.\n",
    "        psd (array): Power Spectral Density values.\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    psd = np.zeros((n_channels, nperseg // 2 + 1))\n",
    "\n",
    "    for ch_idx in range(n_channels):\n",
    "        f, Pxx = plt.psd(data[ch_idx], Fs=fs, NFFT=nperseg, noverlap=noverlap)\n",
    "        # Add a small epsilon to avoid zero values\n",
    "        psd[ch_idx] = Pxx + 1e-10\n",
    "\n",
    "    return f, psd\n",
    "\n",
    "\n",
    "# Get the EEG data using .get_data()\n",
    "eeg_data = raw.get_data()\n",
    "\n",
    "# Set the sampling frequency\n",
    "fs = raw.info['sfreq']\n",
    "\n",
    "# Compute PSD using the custom function\n",
    "freqs, psd = compute_psd(eeg_data, fs)\n",
    "\n",
    "# Plot the PSD\n",
    "plt.figure(figsize=(10, 6))  # Add this line to create a single figure\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    plt.semilogy(freqs, psd[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power/Frequency (dB/Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEfine the time window for epochs around the events\n",
    "t_min, t_max = -1., 4.\n",
    "\n",
    "# Dictionary that maps event names to their corresponding event codes.\n",
    "# Event codes are numeric identifiers that are used to label different type of events or triggers in EEG/MEG data.\n",
    "event_id = {'hands': 2, 'feet': 3}\n",
    "\n",
    "# This is the subject we choose to study. Can be in the range of 1-109 (inclusive)\n",
    "subject = 1\n",
    "\n",
    "# This is the run we choose to study. Can be in the range of 1-14 (inclusive)\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "\n",
    "# Loads in the subject and runs you're interested in\n",
    "raw_fnames = mne.datasets.eegbci.load_data(subject, runs, './EEGData', verbose=False)\n",
    "\n",
    "# Loads in the data file then reads and concatenates the data into the `raw` object\n",
    "raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True, verbose=False) for f in raw_fnames])\n",
    "\n",
    "# Set channel names in the EEG data\n",
    "mne.datasets.eegbci.standardize(raw)\n",
    "\n",
    "# This creates an info object that represents the 10/05 electrode positions \n",
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "\n",
    "# Attaches the montage to the raw data\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# This applies a bandpass filter (finite impulse response) to the data and avoids filtering data near the edge\n",
    "raw.filter(7.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "# This line extracts information from annotations present in the raw data.\n",
    "# Annotations are labels attached to specific points in the data and usually represent events or important time segments.\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "# This line selects specific channel types from the raw data\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, # Datase\n",
    "    events, # Events\n",
    "    event_id, # Event ID\n",
    "    t_min, # Start time\n",
    "    t_max, # End time\n",
    "    proj=True, # Apply SSP projection vectors\n",
    "    picks=picks, # Channels to include\n",
    "    baseline=None, # Baseline interval\n",
    "    preload=True, # Load data into memory\n",
    ")\n",
    "\n",
    "# This creates a new epochs object by copying the original epochs object and cropping the time interval from 1 to 2 seconds.\n",
    "epochs_train = epochs.copy().crop(tmin=1.0, tmax=2.0)\n",
    "\n",
    "# This creates a numpy array that contains the labels for each epoch. \n",
    "# The labels are stored in the last column of the events array. \n",
    "# The labels are stored as integers, but we want them to be 0 and 1. \n",
    "# We can subtract 2 from the labels to get the desired values.\n",
    "labels = epochs.events[:, -1] - 2\n",
    "\n",
    "epochs.plot(n_channels=1, n_epochs=1, scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "# Keeps track of an empty list called scores for the cross-validation procedure\n",
    "scores = []\n",
    "# This extracts the data as a numpy array from the MNE object\n",
    "epochs_data = epochs.get_data()\n",
    "# This extracts the data from the epochs_train object\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "# This line creates a cross-validation (CV) generator using the ShuffleSplit method\n",
    "cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "# This line creates the actual cross-validation splits using the splits method of the CV generator\n",
    "cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = mne.decoding.CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([(\"CSP\", csp), (\"LDA\", lda)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=None)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1.0 - class_balance)\n",
    "print(\n",
    "    \"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance)\n",
    ")\n",
    "\n",
    "# This code above sets up a classification pipeline that includes CSP for feature extraction and LDA as the classifier\n",
    "# It then performs cross-validation using the pipeline and prints the average classification accuracy and chance level of classification accuracy.\n",
    "# This code aims to evaluate the performance of the classifier on the given EEG data and the corresponding labels using cross-validation\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "csp.plot_patterns(epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = raw.info[\"sfreq\"]\n",
    "w_length = int(sfreq * 0.5)  # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "    X_test = csp.transform(epochs_data_train[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = csp.transform(epochs_data[test_idx][:, :, n : (n + w_length)])\n",
    "        score_this_window.append(lda.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.0) / sfreq + epochs.tmin\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label=\"Score\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.title(\"Classification score over time\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
