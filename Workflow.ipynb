{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the data, we'll use the Data folder which contains ways to download data. Here we'll start off by using the EEG_BCI motor imagery dataset.\n",
    "\n",
    "If we want to download the entire dataset, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import download_EEGBCI\n",
    "\n",
    "if input(\"Are you sure you want to download the entire dataset? (Y/N)\") in \"Yy\":\n",
    "    total_subjects = list(range(1, 110))\n",
    "    runs = list(range(1, 15))\n",
    "    download_EEGBCI(total_subjects, runs, './EEGData', False)\n",
    "    print(\"Downloaded everything!\")\n",
    "\n",
    "else:\n",
    "    print(\"Download cancelled.\")\n",
    "\n",
    "\n",
    "# Only downloading a subset of the dataset\n",
    "subjects = [x for x in range(1,50)]\n",
    "runs = [1, 2]\n",
    "download_EEGBCI(subjects, runs, './EEGData', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is critical for actually getting the data into the ML algorithms. To do this, we'll have to rely on MNE's import functions to load the data into a format that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0'\n",
    "\n",
    "subdirectories = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "\n",
    "opened_files = []\n",
    "closed_files = []\n",
    "\n",
    "for subdirectory in subdirectories:\n",
    "    files = os.listdir(subdirectory)\n",
    "    \n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            \n",
    "            if file[-6:] == '01.edf':\n",
    "                # This is data for eyes opened\n",
    "                eyes_opened = os.path.join(subdirectory, file)\n",
    "                print(eyes_opened)\n",
    "                opened_files.append(eyes_opened)\n",
    "\n",
    "            if file[-6:] == '02.edf':\n",
    "                # This is data for eyes closed\n",
    "                eyes_closed = os.path.join(subdirectory, file)\n",
    "                print(eyes_closed)\n",
    "                closed_files.append(eyes_closed)\n",
    "    else:\n",
    "        print(f\"No files found in {subdirectory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Detailed Ways of Working With MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/\"\n",
    "raw = mne.io.read_raw_edf('./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R01.edf', preload=True)\n",
    "annotations = raw.annotations\n",
    "annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_descriptions, event_counts = np.unique(annotations.description, return_counts=True)\n",
    "\n",
    "# Print event descriptions and their counts\n",
    "for desc, count in zip(event_descriptions, event_counts):\n",
    "    print(f\"Event: {desc}, Count: {count}\")\n",
    "\n",
    "# Select specific event type (replace 'event_type' with your desired event description)\n",
    "event_type = 'event_type'\n",
    "events = annotations[annotations.description == event_type]\n",
    "\n",
    "# Print out event onset times and durations\n",
    "for idx, event in enumerate(events):\n",
    "    print(f\"Event {idx + 1}: Onset: {event['onset']:.2f}, Duration: {event['duration']:.2f}\")\n",
    "\n",
    "# Replace 'your_file.edf' with the actual path to your EDF file\n",
    "raw =  mne.io.read_raw_edf('./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf', preload=True)\n",
    "\n",
    "# Get EEG data for all channels\n",
    "eeg_data = raw.get_data()\n",
    "\n",
    "# Print the shape of the EEG data array\n",
    "print(\"EEG data shape:\", eeg_data.shape)\n",
    "\n",
    "# List of EDF file paths\n",
    "edf_files = ['./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf', \n",
    "'./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf',\n",
    "'./EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf']\n",
    "\n",
    "# List comprehension to read all EDF files\n",
    "raw_list = [mne.io.read_raw_edf(edf_file, preload=True) for edf_file in edf_files]\n",
    "\n",
    "# Extract EEG data for all channels from each raw object\n",
    "eeg_data_list = [raw.get_data() for raw in raw_list]\n",
    "\n",
    "# Print the shape of the EEG data arrays for each file\n",
    "for idx, eeg_data in enumerate(eeg_data_list):\n",
    "    print(f\"EEG data shape for file {edf_files[idx]}:\", eeg_data.shape)\n",
    "\n",
    "raw_list[0].plot(scalings='auto', title='EEG Channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_plot(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
    "    eeg_data = data.get_data()\n",
    "    time = data.times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for ch_idx in range(eeg_data.shape[0]):\n",
    "        plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('EEG Data for All Channels')\n",
    "    return plt.show()\n",
    "\n",
    "def double_plot(file1, file2):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    fig.suptitle('Eyes Opened vs Eyes Closed')\n",
    "\n",
    "    data1 = mne.io.read_raw_edf(file1, preload=True, verbose=False)\n",
    "    data1.filter(1.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\", verbose=False)\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800, verbose=False)\n",
    "    ica.fit(data1, verbose=False)\n",
    "    ica.exclude = [1, 2]\n",
    "    data1 = ica.apply(data1, verbose=False)\n",
    "\n",
    "    \n",
    "    data2 = mne.io.read_raw_edf(file2, preload=True, verbose=False)\n",
    "    data2.filter(1.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\", verbose=False)\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800, verbose=False)\n",
    "    ica.fit(data2, verbose=False)\n",
    "    ica.exclude = [1, 2]\n",
    "    data2 = ica.apply(data2, verbose=False)\n",
    "    \n",
    "\n",
    "    good_channels1 = data1.info['ch_names']\n",
    "    good_channels2 = data2.info['ch_names']\n",
    "\n",
    "    eeg_data1 = data1.get_data(picks=good_channels1)\n",
    "    eeg_data2 = data2.get_data(picks=good_channels2)\n",
    "\n",
    "    time = data1.times\n",
    "\n",
    "    ax1.plot(time, eeg_data1[0])\n",
    "    ax1.set_title('Eyes Opened')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    for ch_idx in range(eeg_data1.shape[0]):\n",
    "        ax1.plot(time, eeg_data1[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    ax1.set_xlim(0, 5)\n",
    "    ax1.set_ylim(-0.0002, 0.0002)\n",
    "\n",
    "    ax2.plot(time, eeg_data2[0])\n",
    "    ax2.set_title('Eyes Closed')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Amplitude')\n",
    "    for ch_idx in range(eeg_data2.shape[0]):\n",
    "        ax2.plot(time, eeg_data2[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "    ax2.set_xlim(0, 5)\n",
    "    ax2.set_ylim(-0.0002, 0.0002)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd(fmax=50).plot(picks=\"data\", exclude=\"bads\")\n",
    "raw.plot(duration=5, n_channels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw EEG data\n",
    "edf_file = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R01.edf'\n",
    "raw = mne.io.read_raw_edf(edf_file, preload=True, verbose=False)\n",
    "\n",
    "\n",
    "def compute_psd(data, fs, nperseg=256, noverlap=None):\n",
    "    \"\"\"\n",
    "    Compute Power Spectral Density (PSD) using the Welch method.\n",
    "\n",
    "    Parameters:\n",
    "        data (array): EEG data array with shape (n_channels, n_samples).\n",
    "        fs (float): Sampling frequency.\n",
    "        nperseg (int): Length of each segment for PSD estimation.\n",
    "        noverlap (int): Number of overlapping samples between segments.\n",
    "    \n",
    "    Returns:\n",
    "        freqs (array): Frequency values.\n",
    "        psd (array): Power Spectral Density values.\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    psd = np.zeros((n_channels, nperseg // 2 + 1))\n",
    "\n",
    "    for ch_idx in range(n_channels):\n",
    "        f, Pxx = plt.psd(data[ch_idx], Fs=fs, NFFT=nperseg, noverlap=noverlap)\n",
    "        # Add a small epsilon to avoid zero values\n",
    "        psd[ch_idx] = Pxx + 1e-10\n",
    "\n",
    "    return f, psd\n",
    "\n",
    "\n",
    "# Get the EEG data using .get_data()\n",
    "eeg_data = raw.get_data()\n",
    "#eeg_data = large_closed_data[0]\n",
    "\n",
    "# Set the sampling frequency\n",
    "fs = raw.info['sfreq']\n",
    "\n",
    "# Compute PSD using the custom function\n",
    "freqs, psd = compute_psd(eeg_data, fs)\n",
    "\n",
    "# Plot the PSD\n",
    "plt.figure(figsize=(10, 6))  # Add this line to create a single figure\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    plt.semilogy(freqs, psd[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power/Frequency (dB/Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_plot(opened_files[0])\n",
    "\n",
    "for i in range(3):\n",
    "    double_plot(opened_files[i], closed_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = raw_list[0].get_data()\n",
    "time = raw_list[0].times\n",
    "\n",
    "# Plot EEG data for all channels using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning with MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEfine the time window for epochs around the events\n",
    "t_min, t_max = -1., 4.\n",
    "\n",
    "# Dictionary that maps event names to their corresponding event codes.\n",
    "# Event codes are numeric identifiers that are used to label different type of events or triggers in EEG/MEG data.\n",
    "event_id = {'hands': 2, 'feet': 3}\n",
    "\n",
    "# This is the subject we choose to study. Can be in the range of 1-109 (inclusive)\n",
    "subject = 1\n",
    "\n",
    "# This is the run we choose to study. Can be in the range of 1-14 (inclusive)\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "\n",
    "# Loads in the subject and runs you're interested in\n",
    "raw_fnames = mne.datasets.eegbci.load_data(subject, runs, './EEGData', verbose=False)\n",
    "\n",
    "# Loads in the data file then reads and concatenates the data into the `raw` object\n",
    "raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True, verbose=False) for f in raw_fnames])\n",
    "\n",
    "# Set channel names in the EEG data\n",
    "mne.datasets.eegbci.standardize(raw)\n",
    "\n",
    "# This creates an info object that represents the 10/05 electrode positions \n",
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "\n",
    "# Attaches the montage to the raw data\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# This applies a bandpass filter (finite impulse response) to the data and avoids filtering data near the edge\n",
    "raw.filter(7.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "# This line extracts information from annotations present in the raw data.\n",
    "# Annotations are labels attached to specific points in the data and usually represent events or important time segments.\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "# This line selects specific channel types from the raw data\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, # Datase\n",
    "    events, # Events\n",
    "    event_id, # Event ID\n",
    "    t_min, # Start time\n",
    "    t_max, # End time\n",
    "    proj=True, # Apply SSP projection vectors\n",
    "    picks=picks, # Channels to include\n",
    "    baseline=None, # Baseline interval\n",
    "    preload=True, # Load data into memory\n",
    ")\n",
    "\n",
    "# This creates a new epochs object by copying the original epochs object and cropping the time interval from 1 to 2 seconds.\n",
    "epochs_train = epochs.copy().crop(tmin=1.0, tmax=2.0)\n",
    "\n",
    "# This creates a numpy array that contains the labels for each epoch. \n",
    "# The labels are stored in the last column of the events array. \n",
    "# The labels are stored as integers, but we want them to be 0 and 1. \n",
    "# We can subtract 2 from the labels to get the desired values.\n",
    "labels = epochs.events[:, -1] - 2\n",
    "\n",
    "epochs.plot(n_channels=1, n_epochs=1, scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "# Keeps track of an empty list called scores for the cross-validation procedure\n",
    "scores = []\n",
    "# This extracts the data as a numpy array from the MNE object\n",
    "epochs_data = epochs.get_data()\n",
    "# This extracts the data from the epochs_train object\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "# This line creates a cross-validation (CV) generator using the ShuffleSplit method\n",
    "cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "# This line creates the actual cross-validation splits using the splits method of the CV generator\n",
    "cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = mne.decoding.CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([(\"CSP\", csp), (\"LDA\", lda)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=None)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1.0 - class_balance)\n",
    "print(\n",
    "    \"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance)\n",
    ")\n",
    "\n",
    "# This code above sets up a classification pipeline that includes CSP for feature extraction and LDA as the classifier\n",
    "# It then performs cross-validation using the pipeline and prints the average classification accuracy and chance level of classification accuracy.\n",
    "# This code aims to evaluate the performance of the classifier on the given EEG data and the corresponding labels using cross-validation\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "csp.plot_patterns(epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = raw.info[\"sfreq\"]\n",
    "w_length = int(sfreq * 0.5)  # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "    X_test = csp.transform(epochs_data_train[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = csp.transform(epochs_data[test_idx][:, :, n : (n + w_length)])\n",
    "        score_this_window.append(lda.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.0) / sfreq + epochs.tmin\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label=\"Score\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.title(\"Classification score over time\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_open_data = []\n",
    "# This is a list of all the data for eyes opened\n",
    "large_closed_data = []\n",
    "# This is a list of all the data for eyes closed\n",
    "\n",
    "for data in opened_files:\n",
    "    large_open_data.append(mne.io.read_raw_edf(data, preload=True, verbose=False).get_data(verbose=False))\n",
    "\n",
    "for data in closed_files:\n",
    "    large_closed_data.append(mne.io.read_raw_edf(data, preload=True, verbose=False).get_data(verbose=False))\n",
    "\n",
    "# This is the number of files for eyes opened\n",
    "print(large_open_data.__len__())\n",
    "# This is the number of files for eyes closed\n",
    "print(large_closed_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With preprocessing:\n",
    "for data in opened_files:\n",
    "    data1 = mne.io.read_raw_edf(data, preload=True, verbose=False)\n",
    "    data1.filter(1.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\", verbose=False)\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800, verbose=False)\n",
    "    ica.fit(data1, verbose=False)\n",
    "    ica.exclude = [1, 2]\n",
    "    data1 = ica.apply(data1, verbose=False)\n",
    "\n",
    "    good_channels1 = data1.info['ch_names']\n",
    "\n",
    "    eeg_data1 = data1.get_data(picks=good_channels1)\n",
    "\n",
    "    large_open_data.append(eeg_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently there are issues with index 13\n",
    "\n",
    "for i in range(len(large_open_data)):\n",
    "    if large_open_data[i].shape != (64, 9760):\n",
    "        print(i)\n",
    "        print(large_open_data[i].shape)\n",
    "\n",
    "large_open_data.pop(13)\n",
    "large_closed_data.pop(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of arrays into a NumPy array\n",
    "main_array = np.array([large_closed_data]).squeeze()\n",
    "\n",
    "# Calculate the average along the first axis (axis 0)\n",
    "averaged_array_cl = np.mean(main_array, axis=0)\n",
    "\n",
    "\n",
    "# Convert the list of arrays into a NumPy array\n",
    "main_array = np.array([large_open_data]).squeeze()\n",
    "\n",
    "# Calculate the average along the first axis (axis 0)\n",
    "averaged_array_op = np.mean(main_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = averaged_array_op\n",
    "time = range(9760)\n",
    "\n",
    "# Plot EEG data for all channels using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(64):\n",
    "    plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.ylim(-0.00010, 0.00010)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = averaged_array_cl\n",
    "time = range(9760)\n",
    "\n",
    "# Plot EEG data for all channels using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(64):\n",
    "    plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.ylim(-0.00010, 0.00010)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some unaveraged data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = raw_list[0].get_data()\n",
    "time = raw_list[0].times\n",
    "\n",
    "# Plot EEG data for all channels using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = raw_list[1].get_data()\n",
    "time = raw_list[0].times\n",
    "\n",
    "# Plot EEG data for all channels using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for ch_idx in range(eeg_data.shape[0]):\n",
    "    if ch_idx == 1:\n",
    "        plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}', alpha=1, color= 'green', zorder=25)\n",
    "    else:\n",
    "        plt.plot(time, eeg_data[ch_idx], label=f'Channel {ch_idx + 1}', alpha=0.1, color='grey')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('EEG Data for All Channels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to start off by loading in the datasets we'll be using. For now, we'll be using the motor imagery dataset. We've already called it into this file with `large_closed_data` and `large_open_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_closed_data.__len__(), large_open_data.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at an individual sample first and try to figure out what we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_closed_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see than an individual sample contains 64 channels and 9760 time points per sample. We'll see that this will stay the same for all of the EEG BCI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_closed_data[0][0].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.label = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.label\n",
    "        return self.data[index], label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(large_closed_data)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(large_closed_data), type(large_closed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [torch.tensor(arr) for arr in large_closed_data]\n",
    "\n",
    "# Convert the list of PyTorch tensors to a single PyTorch tensor\n",
    "closed = torch.stack(tensor_list) * 100000\n",
    "\n",
    "\n",
    "tensor_list = [torch.tensor(arr) for arr in large_open_data]\n",
    "\n",
    "# Convert the list of PyTorch tensors to a single PyTorch tensor\n",
    "opened = torch.stack(tensor_list) * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "eyes_closed_labels = [0] * len(closed)\n",
    "eyes_open_labels = [1] * len(opened)\n",
    "\n",
    "# Combine datasets and labels\n",
    "combined_data = torch.cat((closed, opened), dim=0)\n",
    "combined_labels = eyes_closed_labels + eyes_open_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.__len__(), combined_labels.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    combined_data, combined_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            dataset = self.transform(dataset)\n",
    "\n",
    "        return dataset, label\n",
    "\n",
    "# Define transformations (resize, normalize, augment, etc.) if needed\n",
    "transform = transforms.Compose([\n",
    "])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = CustomDataset(train_data, train_labels, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_data, val_labels, transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, test_labels, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN1D, self).__init__()\n",
    "        # 1D Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # Max-pooling layers\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 4880, 128)  # Adjusted for input size (64, 9760)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Output has 2 classes (0 and 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4880)  # Adjusted for input size (64, 9760)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class EEGClassificationModel(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(EEGClassificationModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=num_channels, out_channels=32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 4879, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()  # Convert input to float data type\n",
    "        x = torch.relu(self.conv1d(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 4879)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = SimpleCNN1D()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 64\n",
    "num_classes = 2  # Change this based on your classification task\n",
    "\n",
    "# Create an instance of the model\n",
    "model = EEGClassificationModel(num_channels, num_classes)\n",
    "\n",
    "# Assuming you have EEG data as a tensor with shape (batch_size, num_channels, num_time_steps)\n",
    "# Forward pass\n",
    "output = model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = SimpleCNN1D()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Validation loop (optional)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
