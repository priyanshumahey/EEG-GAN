{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_channel_plot(data, channel, title):\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(data[channel, :])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_channels(data, title):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(data.T)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_channels_subplots(data):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(64):\n",
    "        plt.subplot(8, 8, i+1)\n",
    "        plt.plot(data[i, :])\n",
    "        plt.title(f\"Channel {i}\")\n",
    "    plt.show()\n",
    "\n",
    "main_folder = './EEGData/MNE-eegbci-data/files/eegmmidb/1.0.0'\n",
    "subdirectories = [f.path for f in os.scandir(main_folder) if f.is_dir()]\n",
    "opened_files = []\n",
    "closed_files = []\n",
    "\n",
    "for subdirectory in subdirectories:\n",
    "    files = os.listdir(subdirectory)\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            if file[-6:] == '01.edf':\n",
    "                # This is data for eyes opened\n",
    "                eyes_opened = os.path.join(subdirectory, file)\n",
    "                opened_files.append(eyes_opened)\n",
    "            if file[-6:] == '02.edf':\n",
    "                # This is data for eyes closed\n",
    "                eyes_closed = os.path.join(subdirectory, file)\n",
    "                closed_files.append(eyes_closed)\n",
    "    else:\n",
    "        print(f\"No files found in {subdirectory}\")\n",
    "\n",
    "large_open_data_raw = []\n",
    "large_closed_data_raw = []\n",
    "\n",
    "flag = True\n",
    "\n",
    "for i in range(len(opened_files)):\n",
    "    if i not in [1,4,5,6,12,13,15,17,19,22,29,31,33,34.47,50,51,58,60,71,76,77,79,81,86,87,88,90,95,100]:\n",
    "        data1 = mne.io.read_raw_edf(opened_files[i], preload=True, verbose=False).get_data(verbose=False)\n",
    "        data2 = mne.io.read_raw_edf(closed_files[i], preload=True, verbose=False).get_data(verbose=False)\n",
    "        for j in range(max(len(data1), len(data2))):\n",
    "            if len(data1[j]) != 9760 or len(data2[j]) != 9760:\n",
    "                flag = False\n",
    "        if flag:\n",
    "            large_open_data_raw.append(data1)\n",
    "            large_closed_data_raw.append(data2)\n",
    "        flag = True\n",
    "\n",
    "print(\"Length of open dataset:\", large_open_data_raw.__len__())\n",
    "print(\"Length of closed dataset:\", large_closed_data_raw.__len__())\n",
    "\n",
    "for i in range(len(large_open_data_raw)):\n",
    "    if len(large_open_data_raw[i]) != 64:\n",
    "        print(i)\n",
    "    for j in range(len(large_open_data_raw[i])):\n",
    "        if len(large_open_data_raw[i][j]) != 9760:\n",
    "            print(i)\n",
    "\n",
    "for i in range(len(large_closed_data_raw)):\n",
    "    if len(large_closed_data_raw[i]) != 64:\n",
    "        print(i)\n",
    "    for j in range(len(large_closed_data_raw[i])):\n",
    "        if len(large_closed_data_raw[i][j]) != 9760:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwannted variables\n",
    "del opened_files\n",
    "del closed_files\n",
    "del subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
